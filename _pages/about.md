---
layout: about
title: About
permalink: /
description: 

profile:
  align: left
  image: me2.png
  address: 

news: true  # includes a list of news items
selected_papers: true # includes a list of papers marked as "selected={true}"
social: true  # includes social icons at the bottom of the page
---

Senior Researcher, Microsoft Research Asia<br>
Building 2, No. 5 Danling Street, Haidian District, Beijing, China<br>
jindongwang [at] outlook.com, jindong.wang [at] microsoft.com<br>
[Google scholar](https://scholar.google.com/citations?user=hBZ_tKsAAAAJ) | [DBLP](https://dblp.org/pid/19/2969-1.html) | [Github](https://github.com/jindongwang) || [Twitter/X](https://twitter.com/jd92wang) | [Zhihu](https://www.zhihu.com/people/jindongwang) | [Wechat](http://jd92.wang/assets/img/wechat_public_account.jpg) | [Bilibili](https://space.bilibili.com/477087194) || [CV](https://go.jd92.wang/cv) [CV (Chinese)](https://go.jd92.wang/cvchinese)

Dr. Jindong Wang is currently a Senior Researcher at Microsoft Research Asia. He obtained his Ph.D from Institute of Computing Technology, Chinese Academy of Sciences in 2019. In 2018, he visited Prof. Qiang Yangâ€™s group at Hong Kong University of Science and Technology. His research interest includes robust machine learning, transfer learning, semi-supervised learning, and federated learning. His recent interest is large language models. He has published over 50 papers with 8000+ citations at leading conferences and journals such as ICLR, NeurIPS, TPAMI, TKDE, IJCV etc. He has 6 highly cited papers according to [Google Scholar metrics](https://scholar.google.com/citations?view_op=top_venues) and 6 Huggingface Featured papers. He received the best paper award at ICCSE'18 and IJCAI'19 federated learning workshop and the prestigous excellent Ph.D thesis award (only 1 at ICT each year). In 2023, he was selected by Stanford University as one of the [World's 2% Scientists](https://ecebm.com/2023/10/04/stanford-university-names-worlds-top-2-scientists-2023/) and one of the [AI Most Influential Scholars](https://www.aminer.cn/ai2000?domain_ids=5dc122672ebaa6faa962c2a4) by AMiner. He serves as the associate editor of IEEE Transactions on Neural Networks and Learning Systems (TNNLS), guest editor for ACM Transactions on Intelligent Systems and Technology (TIST), senior program committee member of IJCAI and AAAI, and reviewers for top conferences and journals like ICML, NeurIPS, ICLR, CVPR, TPAMI, AIJ etc. He leads several impactful open-source projects, including [transferlearning](https://github.com/jindongwang/transferlearning), [PromptBench](https://github.com/microsoft/promptbench), [torchSSL](https://github.com/torchssl/torchssl), [USB](https://github.com/microsoft/Semi-superised-learning), [personalizedFL](https://github.com/microsoft/PersonalizedFL), and [robustlearn](https://github.com/microsoft/robustlearn), which received over 16K stars on Github. He published a textbook [Introduction to Transfer Learning](http://jd92.wang/tlbook) to help starters quickly learn transfer learning. He gave tutorials at [IJCAI'22](https://dgresearch.github.io/), [WSDM'23](https://dgresearch.github.io/), [KDD'23](https://mltrust.github.io/), and [AAAI'24](https://ood-timeseries.github.io/).

**Research interest:** robust machine learning, OOD / domain generalization, transfer learning, semi-supervised learning, federated learning, and related applications.

**Recent interest:** Large Language Models (LLMs) [evaluation](https://llm-eval.github.io/) and [enhancement](https://llm-enhance.github.io/). See this [page](https://jd92.wang/research/) for more details. *Interested in [internship](https://zhuanlan.zhihu.com/p/102558267) or collaboration? Contact me.* I'm experimenting a new form of research collaboration. You can click [here](https://forms.office.com/r/32Fs6uAjT6) if you are interested!

**Announcement:** Call for papers for ACM TIST special issue on Evaluations of Large Langauge Models! [[more](https://dl.acm.org/pb-assets/static_journal_pages/tist/pdf/TIST_CfP_LLMS-1696884403733.pdf)]


